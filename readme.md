# ğŸ§‘â€âš–ï¸ AI Lawyer â€“ RAG-Powered PDF Q&A Chatbot

A powerful RAG (Retrieval-Augmented Generation) system using **Deepseek**, **LangChain**, and **Streamlit**. This setup allows you to chat with PDFs and get accurate answers to complex questions about your local documents.

This project walks through the entire process step by step:
- Setting up **Ollamaâ€™s Deepseek-r1** LLM model (known for its strong reasoning abilities)
- Integrating it with a LangChain-powered RAG pipeline
- Building a user-friendly **Streamlit** interface for real-time querying of your PDFs

Whether you're exploring Deepseek, reasoning models, LangChain, or building your own document-aware AI chatbot, this project has you covered.

---

## ğŸ“¦ Features

- ğŸ“¤ Upload any legal PDF  
- ğŸ¤– Ask natural language questions  
- ğŸ§  RAG-based answers using DeepSeek + Groq LLM  
- âš¡ FAISS-powered similarity search  
- â™»ï¸ Intelligent caching of PDF embeddings  
- ğŸ’¬ Clear chat or download full conversation logs  

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ main.py                # Streamlit frontend and app logic
â”œâ”€â”€ vector_database.py     # PDF processing, embeddings, vector DB logic
â”œâ”€â”€ rag_pipeline.py        # Prompt template, LLM response generation
â”œâ”€â”€ pdfs/                  # Stores uploaded PDFs
â”œâ”€â”€ vectorstore/cache/     # Caches FAISS vector stores
â””â”€â”€ README.md              # You're here!
```

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/ai-lawyer-chatbot.git
cd ai-lawyer-chatbot
```

### 2. Create and Activate Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

Example `requirements.txt`:

```text
streamlit
langchain
langchain-community
langchain-core
langchain-groq
faiss-cpu
pdfplumber
```

> âš ï¸ Ensure Ollama is installed and the DeepSeek model is available locally or via Groq.

---

### 4. Run the App

```bash
streamlit run main.py
```

---

## ğŸ§  How It Works

1. **Upload PDF** â†’ PDF is saved and processed  
2. **Vectorization** â†’ Text chunks are embedded using `deepseek-r1:14b`  
3. **Caching** â†’ Embeddings are cached locally using a hash of PDF content  
4. **Query** â†’ User's question is matched with similar chunks via FAISS  
5. **LLM Answer** â†’ Only relevant context is passed to the LLM to generate an answer

---

## âœ… Example Use Case

Upload a legal document (e.g., a contract or act), then ask:

> â€œWhat are the conditions for termination?â€

The bot will retrieve only the relevant section and answer accordingly.

---

## ğŸ§ª Future Enhancements

- ğŸ” Streamed response  
- ğŸ” Support for multi-PDF search  
- â˜ï¸ Upload result to GitHub/Google Drive  
- ğŸŒ Web deployment with Docker  

---

## ğŸ¤ Contributing

Pull requests and feedback are welcome! Let's make legal AI simpler together.

---

## ğŸ“œ License

MIT License. Use at your own legal discretion ğŸ˜„
